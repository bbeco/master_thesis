\chapter{Conclusion}
\lhead{\chaptername~\thechapter. \emph{Conclusion}}

In this work, we have proposed a SfM pipeline for full spherical cameras that works directly on 360 video.
As we pointed out in Section~\ref{sec:contribution} and
Section~\ref{subsec:related_work}, our contribution includes:
%
\begin{itemize}
	\item a simple but effective frame filter that selects the non-redundant frames to be processed based on visual
	information only;
	\item a new approach to estimate poses that exploits both frontal and rear
	points;
	\item a novel block-matching algorithm for disparity map estimation for
	equirectangular images.
\end{itemize}
%
We have showed the effectiveness of our pipeline by testing it on 
both computer-generated and real-world environments.
Even though our approach is extremely straightforward, especially when compared to more advanced pipeline (e.g.,~\cite{schonberger2016structure}, it still offers high-quality results in terms of
poses estimation precision and environment reconstruction.

\section{Future Work}\label{sec:future_work}
Our SfM pipeline employs existing correspondences between adjacent frames only.
This is because we use video sequences as input data, thus the presence of
the same features of the current frame in the next one is a natural consequence
of the particular nature of our input.
As we pointed out in Section~\ref{subsec:limitations}, this particular choice
for feature matching can be a problem when not enough feature points can be
tracked in a part of the video sequence. In this case, the camera pose
estimation is invalid from that point, and it will continue to remain invalid.
The current implementation of our pipeline does not deal with this problem,
hence, it is up to the user to remove the critical frames and produce two
separate reconstruction that can merged together.

Another solution to make the camera pose estimation more robust is to 
exploit the loop-closure detection as the SLAM algorithms done (Section~\ref{sec:sfm_vo_slam}).
Loop closure is the process of detecting the camera crossing a previously
visited place. The identified loop can be used as an additional constraint
to improve the camera pose estimation globally.

Another interesting improvement of the pipeline can be to use more robust features detection and matching algorithm more specific for this type of images.
Some of the possible alternative algorithms are ASIFT~\cite{morel2009asift}, which
 can perform better in case of views with very tilted cameras, and
BRISKS~\cite{guan2017brisks}, a feature detector inspired by
BRISK~\cite{leutenegger2011brisk} and designed specifically for full spherical
images.

Another approach to improve local motion estimation is to
introduce a procedure to extract
features that are evenly distributed across an image. The more
keypoints are spread over an image, the more accurate is the local motion
estimation~\cite{irschara2009structure,schonberger2016structure}.
The development of this new feature in the current pipeline 
has just been planned to be finished in short time. 
