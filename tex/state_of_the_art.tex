\chapter{State of the Art}
\label{ch:state_of_the_art}
We start this chapter with the description of a traditional VO pipeline for 
perspective cameras. We explain the fundamental steps for robust motion 
estimation and the challenges issued by VO with full spherical cameras.

\section{Perspective SfM}
A great resource about the state of the art for Visual Odometry and Structure 
from Motion techniques is the couple of articles by Scaramuzza,  
\cite{scaramuzzaVisualOdometryI} and \cite{scaramuzzaVisualOdometryII}.

The work done in these topics is extensive but all the approaches the 
researches followed so far include similar pipelines.
Indeed the idea is rather simple: compute the relative motion for each image
pair, then compose these motions to obtain the absolute camera position and 
orientation. Finally run an optimization procedure to reduce drift.
The differences are in the type of input data, motion estimation algorithm,
 optimization procedure and additional constraints considered.

For generic SfM researches, the input data is a set of traditional pictures of 
the same environment from different point of view. The pictures can be taken by 
different cameras with unknown parameters and in different moments.

\textit{Visual Odometry} is based on SfM techniques, 
in this case, the input data is usually a sequence 
of images from a video stream. Many studies targeted different hardware setup 
but the specific image capturing device is usually either a single perspective 
camera or a stereo imaging rig. The computer vision literature refers to the
former case with the term \textit{monocular VO} while it uses \textit{stereo VO}
to describe the latter.

Even though perspective cameras have been the first choice in many studies, 
the researchers used other devices, like the ones described in 
\ref{sec:cameraclassification}.

We use the terms \textit{perspective} or \textit{traditional SfM} for the 
SfM pipelines for perspective cameras.

\subsection{VO Problem}
We have already described the objective of VO in the previous section; we
introduce now the notations we use from now on. These notations are the same 
ones used by Scaramuzza in \cite{scaramuzzaVisualOdometryI}.

Let first assume \(k\) indicates the time instant; 
\(I_{0:n} \) is the set of frames 
captured with our camera while it is moving in the environment (let \(I_{k}\) 
be the image taken at instant \(k\)). We call \(C_{0:n}\) the set of camera 
position such that \(C_k\) is the position at the instant \(k\).
If we call \(T_k\) the rigid body transformation of the camera between two
consecutive time instant, we have the following relation:
\begin{equation*}
C_n = C_{n-1} T_n
\end{equation*}
\noindent with \(T_k\) that is defined as
\begin{equation*}
	T_k =
	\begin{bmatrix}
	R_k & t_k \\
	0 & 1
	\end{bmatrix}
\end{equation*}

\subsection{Camera Model}

\section{Full Spherical Cameras}
\subsection{Image Format}
If we consider the simplest camera model, 
a perspective image is the result of the intersection between the image plane 
and all the light rays that go from the environment to the center of 
projection inside the camera (see Fig\ref{fig:perscam_model}).
\missingfigure{aggiungere modello camera prospettica}
\label{fig:perscam_model}
On the other hand, the full spherical camera model implies the image plane 
to be the result of the intersection between a sphere and the rays from the 
environment to the center of projection (which is equivalent to the sphere's 
center).
\todo[inline]{aggiungere descrizione coordinate omogenee}

